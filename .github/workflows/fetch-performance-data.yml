name: Fetch Performance Data

on:
  workflow_dispatch:  # Manual trigger
  schedule:
    - cron: '0 0 * * 0'  # Run weekly on Sundays at midnight

jobs:
  fetch-performance:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Needed for pushing changes

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install PyGithub requests

      - name: Fetch performance data
        env:
          # Use a Personal Access Token with organization access
          # You need to create this token with 'repo' and 'read:org' scopes
          GITHUB_PAT: ${{ secrets.ORG_ACCESS_TOKEN }}
        run: |
          python - << 'EOF'
          import os
          import json
          import re
          import requests
          from github import Github
          
          # Initialize GitHub client with organization access
          # Using PAT instead of default GITHUB_TOKEN
          token = os.environ['GITHUB_PAT']  # Changed from GITHUB_TOKEN to GITHUB_PAT
          if not token:
              print("Error: ORG_ACCESS_TOKEN not set. Please add this secret to your repository.")
              exit(1)
              
          g = Github(token)
          org_name = "hsph-bst236"  # The organization name
          
          try:
              # Get the organization
              org = g.get_organization(org_name)
              print(f"Successfully accessed organization: {org_name}")
              
              # List all repositories to debug
              all_repos = list(org.get_repos())
              print(f"Total repositories in organization: {len(all_repos)}")
              print(f"All repository names: {', '.join([r.name for r in all_repos])}")
              
              # Get repositories in the organization with the prefix
              repos = [repo for repo in org.get_repos() if repo.name.startswith("homework-3-")]
              
              if not repos:
                  print(f"No repositories found with prefix 'homework-3-' in the {org_name} organization")
                  exit(0)
                  
              print(f"Found {len(repos)} repositories with prefix 'homework-3-' in the {org_name} organization")
              
              performance_data = []
              
              for repo in repos:
                  repo_name = repo.name
                  print(f"Processing repository: {repo_name}")
                  
                  # Check if the repository has the test workflow
                  try:
                      workflow_runs = repo.get_workflow_runs(workflow_id="test-calculate-temp-r.yml")
                      latest_run = next(iter(workflow_runs), None)
                      
                      if latest_run and latest_run.conclusion == "success":
                          # Get the logs from the run
                          logs = latest_run.download_logs().decode('utf-8')
                          
                          # Extract runtime from logs
                          runtime_match = re.search(r"Rscript calculate_Temp\.R ran in ([\d.]+) seconds", logs)
                          if runtime_match:
                              runtime = float(runtime_match.group(1))
                              performance_data.append({
                                  "repository": repo_name,
                                  "runtime": runtime,
                                  "url": repo.html_url
                              })
                              print(f"Found runtime: {runtime} seconds")
                          else:
                              print(f"Could not find runtime information in logs for {repo_name}")
                      else:
                          status = latest_run.conclusion if latest_run else "No runs found"
                          print(f"No successful test runs found for {repo_name}. Status: {status}")
                  except Exception as e:
                      print(f"Error processing {repo_name}: {str(e)}")
          
          except Exception as e:
              print(f"Error accessing organization {org_name}: {str(e)}")
              exit(1)
          
          # Sort data by runtime (fastest to slowest)
          performance_data.sort(key=lambda x: x["runtime"])
          
          # Save to JSON file
          with open('performance_data.json', 'w') as f:
              json.dump(performance_data, f, indent=2)
          
          # Update README.md
          readme_content = ""
          if os.path.exists('README.md'):
              with open('README.md', 'r') as f:
                  readme_content = f.read()
          
          # Create performance table
          performance_table = "## Performance Results\n\n"
          performance_table += "| Rank | Repository | Runtime (seconds) |\n"
          performance_table += "|------|------------|------------------|\n"
          
          for i, data in enumerate(performance_data, 1):
              repo_name = data['repository']
              repo_url = data['url']
              runtime = data['runtime']
              performance_table += f"| {i} | [{repo_name}]({repo_url}) | {runtime:.4f} |\n"
          
          # Check if README already has a performance section
          if "## Performance Results" in readme_content:
              # Replace existing section
              readme_content = re.sub(
                  r"## Performance Results\n\n[\s\S]*?(?=\n##|$)",
                  performance_table,
                  readme_content
              )
          else:
              # Append performance section
              readme_content += "\n\n" + performance_table
          
          with open('README.md', 'w') as f:
              f.write(readme_content)
          
          print(f"Processed {len(performance_data)} repositories with successful test runs")
          print("Performance data has been saved to performance_data.json and README.md has been updated.")
          EOF

      - name: Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add performance_data.json README.md
          git commit -m "Update performance data [skip ci]" || echo "No changes to commit"
          git push 